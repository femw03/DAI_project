{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-30T09:17:41.338512900Z",
     "start_time": "2024-10-30T09:17:40.922178600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.3)\n",
      "Path to dataset files: C:\\Users\\julia\\.cache\\kagglehub\\datasets\\sachsene\\carla-traffic-signs-images\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"sachsene/carla-traffic-signs-images\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Num GPUs Available: \", torch.cuda.device_count())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-30T09:17:47.644447800Z",
     "start_time": "2024-10-30T09:17:47.624448700Z"
    }
   },
   "id": "1b4ae258c0fccf03"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 8\n",
      "Classes: ['back', 'speed_30', 'speed_60', 'speed_90', 'speed_limit_30', 'speed_limit_40', 'speed_limit_60', 'stop']\n"
     ]
    }
   ],
   "source": [
    "# Paths to the dataset\n",
    "train_dataset_path = os.path.join(\"traffic_signs_images\", \"train\")\n",
    "test_dataset_path = os.path.join(\"traffic_signs_images\", \"test\")\n",
    "\n",
    "# Define the transformations for data augmentation and normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomResizedCrop(32, scale=(0.9, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load the training dataset with validation split\n",
    "train_dataset = datasets.ImageFolder(train_dataset_path, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_dataset_path, transform=transform)\n",
    "\n",
    "\n",
    "# Number and name of classes\n",
    "num_classes = len(train_dataset.classes)\n",
    "print(f'Number of classes: {num_classes}')\n",
    "print('Classes:', train_dataset.classes)\n",
    "\n",
    "\n",
    "# Split indices for training and validation (90% train, 10% validation)\n",
    "train_size = int(0.9 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_indices, val_indices = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Create samplers for the training and validation datasets\n",
    "train_sampler = SubsetRandomSampler(train_indices.indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices.indices)\n",
    "\n",
    "# DataLoader for training, validation, and testing datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, sampler=train_sampler)\n",
    "val_loader = DataLoader(train_dataset, batch_size=32, sampler=val_sampler)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-30T09:17:48.843451300Z",
     "start_time": "2024-10-30T09:17:48.799608800Z"
    }
   },
   "id": "4ecc003fb2fd1a8a"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)  # Adjusted for increased capacity\n",
    "        self.fc2 = nn.Linear(128, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # Conv2D -> ReLU -> MaxPool\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 8 * 8)  # Flatten\n",
    "        x = F.relu(self.fc1(x))  # Dense layer\n",
    "        x = self.fc2(x)  # Output layer with softmax activation\n",
    "        return F.log_softmax(x, dim=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-30T09:17:50.143120900Z",
     "start_time": "2024-10-30T09:17:50.118051700Z"
    }
   },
   "id": "aa708310a172785f"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 1.2388, Train Acc: 0.5277, Val Loss: 0.7094, Val Acc: 0.6971\n",
      "Epoch 2/200, Train Loss: 0.6488, Train Acc: 0.7177, Val Loss: 0.4877, Val Acc: 0.7886\n",
      "Epoch 3/200, Train Loss: 0.5195, Train Acc: 0.7997, Val Loss: 0.3517, Val Acc: 0.9029\n",
      "Epoch 4/200, Train Loss: 0.3011, Train Acc: 0.9034, Val Loss: 0.2390, Val Acc: 0.8914\n",
      "Epoch 5/200, Train Loss: 0.2259, Train Acc: 0.9218, Val Loss: 0.1709, Val Acc: 0.9600\n",
      "Epoch 6/200, Train Loss: 0.1777, Train Acc: 0.9421, Val Loss: 0.0918, Val Acc: 0.9771\n",
      "Epoch 7/200, Train Loss: 0.0841, Train Acc: 0.9746, Val Loss: 0.0578, Val Acc: 0.9886\n",
      "Epoch 8/200, Train Loss: 0.0709, Train Acc: 0.9803, Val Loss: 0.0621, Val Acc: 0.9771\n",
      "Epoch 9/200, Train Loss: 0.0543, Train Acc: 0.9822, Val Loss: 0.0580, Val Acc: 0.9771\n",
      "Epoch 10/200, Train Loss: 0.0708, Train Acc: 0.9797, Val Loss: 0.0794, Val Acc: 0.9714\n",
      "Epoch 11/200, Train Loss: 0.0600, Train Acc: 0.9803, Val Loss: 0.0934, Val Acc: 0.9829\n",
      "Epoch 12/200, Train Loss: 0.0408, Train Acc: 0.9892, Val Loss: 0.0226, Val Acc: 1.0000\n",
      "Epoch 13/200, Train Loss: 0.0398, Train Acc: 0.9886, Val Loss: 0.0333, Val Acc: 0.9829\n",
      "Epoch 14/200, Train Loss: 0.0458, Train Acc: 0.9879, Val Loss: 0.0212, Val Acc: 0.9943\n",
      "Epoch 15/200, Train Loss: 0.0404, Train Acc: 0.9847, Val Loss: 0.0348, Val Acc: 0.9886\n",
      "Epoch 16/200, Train Loss: 0.0249, Train Acc: 0.9936, Val Loss: 0.0199, Val Acc: 0.9943\n",
      "Epoch 17/200, Train Loss: 0.0207, Train Acc: 0.9943, Val Loss: 0.0396, Val Acc: 0.9943\n",
      "Epoch 18/200, Train Loss: 0.0265, Train Acc: 0.9917, Val Loss: 0.0923, Val Acc: 0.9829\n",
      "Epoch 19/200, Train Loss: 0.0445, Train Acc: 0.9886, Val Loss: 0.0366, Val Acc: 0.9771\n",
      "Epoch 20/200, Train Loss: 0.0480, Train Acc: 0.9860, Val Loss: 0.0771, Val Acc: 0.9771\n",
      "Epoch 21/200, Train Loss: 0.0149, Train Acc: 0.9981, Val Loss: 0.0168, Val Acc: 0.9886\n",
      "Epoch 22/200, Train Loss: 0.0096, Train Acc: 0.9987, Val Loss: 0.0061, Val Acc: 1.0000\n",
      "Epoch 23/200, Train Loss: 0.0088, Train Acc: 0.9987, Val Loss: 0.0302, Val Acc: 0.9943\n",
      "Epoch 24/200, Train Loss: 0.0176, Train Acc: 0.9962, Val Loss: 0.0135, Val Acc: 0.9886\n",
      "Epoch 25/200, Train Loss: 0.0205, Train Acc: 0.9930, Val Loss: 0.0110, Val Acc: 1.0000\n",
      "Epoch 26/200, Train Loss: 0.0235, Train Acc: 0.9930, Val Loss: 0.0626, Val Acc: 0.9886\n",
      "Epoch 27/200, Train Loss: 0.0220, Train Acc: 0.9905, Val Loss: 0.0079, Val Acc: 1.0000\n",
      "Epoch 28/200, Train Loss: 0.0140, Train Acc: 0.9949, Val Loss: 0.0050, Val Acc: 1.0000\n",
      "Epoch 29/200, Train Loss: 0.0134, Train Acc: 0.9949, Val Loss: 0.0057, Val Acc: 1.0000\n",
      "Epoch 30/200, Train Loss: 0.0276, Train Acc: 0.9917, Val Loss: 0.0646, Val Acc: 0.9771\n",
      "Epoch 31/200, Train Loss: 0.0096, Train Acc: 0.9968, Val Loss: 0.0272, Val Acc: 0.9886\n",
      "Epoch 32/200, Train Loss: 0.0116, Train Acc: 0.9968, Val Loss: 0.0021, Val Acc: 1.0000\n",
      "Epoch 33/200, Train Loss: 0.0074, Train Acc: 0.9981, Val Loss: 0.0143, Val Acc: 0.9943\n",
      "Epoch 34/200, Train Loss: 0.0157, Train Acc: 0.9936, Val Loss: 0.0308, Val Acc: 0.9829\n",
      "Epoch 35/200, Train Loss: 0.0162, Train Acc: 0.9962, Val Loss: 0.0290, Val Acc: 0.9943\n",
      "Epoch 36/200, Train Loss: 0.0186, Train Acc: 0.9955, Val Loss: 0.0245, Val Acc: 0.9943\n",
      "Epoch 37/200, Train Loss: 0.0124, Train Acc: 0.9975, Val Loss: 0.0061, Val Acc: 0.9943\n",
      "Epoch 38/200, Train Loss: 0.0131, Train Acc: 0.9955, Val Loss: 0.0122, Val Acc: 0.9943\n",
      "Epoch 39/200, Train Loss: 0.0125, Train Acc: 0.9968, Val Loss: 0.0527, Val Acc: 0.9829\n",
      "Epoch 40/200, Train Loss: 0.0190, Train Acc: 0.9949, Val Loss: 0.0137, Val Acc: 0.9886\n",
      "Epoch 41/200, Train Loss: 0.0113, Train Acc: 0.9955, Val Loss: 0.0406, Val Acc: 0.9943\n",
      "Epoch 42/200, Train Loss: 0.0056, Train Acc: 0.9987, Val Loss: 0.0105, Val Acc: 0.9943\n",
      "Epoch 43/200, Train Loss: 0.0044, Train Acc: 0.9981, Val Loss: 0.0094, Val Acc: 1.0000\n",
      "Epoch 44/200, Train Loss: 0.0053, Train Acc: 0.9981, Val Loss: 0.0469, Val Acc: 0.9829\n",
      "Epoch 45/200, Train Loss: 0.0059, Train Acc: 0.9975, Val Loss: 0.0109, Val Acc: 0.9943\n",
      "Epoch 46/200, Train Loss: 0.0046, Train Acc: 0.9981, Val Loss: 0.0024, Val Acc: 1.0000\n",
      "Epoch 47/200, Train Loss: 0.0072, Train Acc: 0.9968, Val Loss: 0.0218, Val Acc: 0.9886\n",
      "Epoch 48/200, Train Loss: 0.0176, Train Acc: 0.9949, Val Loss: 0.0291, Val Acc: 0.9886\n",
      "Epoch 49/200, Train Loss: 0.0203, Train Acc: 0.9949, Val Loss: 0.0364, Val Acc: 0.9886\n",
      "Epoch 50/200, Train Loss: 0.0249, Train Acc: 0.9930, Val Loss: 0.0311, Val Acc: 0.9886\n",
      "Epoch 51/200, Train Loss: 0.0429, Train Acc: 0.9841, Val Loss: 0.0086, Val Acc: 0.9943\n",
      "Epoch 52/200, Train Loss: 0.0151, Train Acc: 0.9949, Val Loss: 0.0049, Val Acc: 1.0000\n",
      "Epoch 53/200, Train Loss: 0.0089, Train Acc: 0.9981, Val Loss: 0.0010, Val Acc: 1.0000\n",
      "Epoch 54/200, Train Loss: 0.0080, Train Acc: 0.9981, Val Loss: 0.0193, Val Acc: 0.9943\n",
      "Epoch 55/200, Train Loss: 0.0045, Train Acc: 0.9994, Val Loss: 0.0516, Val Acc: 0.9829\n",
      "Epoch 56/200, Train Loss: 0.0096, Train Acc: 0.9968, Val Loss: 0.0017, Val Acc: 1.0000\n",
      "Epoch 57/200, Train Loss: 0.0240, Train Acc: 0.9943, Val Loss: 0.0063, Val Acc: 0.9943\n",
      "Epoch 58/200, Train Loss: 0.0342, Train Acc: 0.9936, Val Loss: 0.0007, Val Acc: 1.0000\n",
      "Epoch 59/200, Train Loss: 0.0448, Train Acc: 0.9854, Val Loss: 0.0287, Val Acc: 0.9943\n",
      "Epoch 60/200, Train Loss: 0.0085, Train Acc: 0.9975, Val Loss: 0.0031, Val Acc: 1.0000\n",
      "Epoch 61/200, Train Loss: 0.0035, Train Acc: 1.0000, Val Loss: 0.0056, Val Acc: 1.0000\n",
      "Epoch 62/200, Train Loss: 0.0106, Train Acc: 0.9968, Val Loss: 0.0374, Val Acc: 0.9943\n",
      "Early stopping after 62 epochs\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model, loss function, and optimizer\n",
    "model = CNNModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Early stopping and model checkpoint functionality\n",
    "best_val_acc = 0\n",
    "patience = 50\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 200\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_acc = val_correct / val_total\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {running_loss/len(train_loader):.4f}, '\n",
    "          f'Train Acc: {train_acc:.4f}, Val Loss: {val_loss/len(val_loader):.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "    # Early stopping based on validation accuracy\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), 'BEST_Traffic_Sign_Model.pth')  # Save best model\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve == patience:\n",
    "        print(f'Early stopping after {epoch+1} epochs')\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-30T09:21:44.245077700Z",
     "start_time": "2024-10-30T09:17:50.939769600Z"
    }
   },
   "id": "46e89f123c8b2ffe"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\AppData\\Local\\Temp\\ipykernel_36304\\3880124287.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('BEST_Traffic_Sign_Model.pth'))  # Load best model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9505\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "model.load_state_dict(torch.load('BEST_Traffic_Sign_Model.pth'))  # Load best model\n",
    "model.eval()\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_acc = test_correct / test_total\n",
    "print(f'Test accuracy: {test_acc:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-30T09:24:16.328567400Z",
     "start_time": "2024-10-30T09:24:07.198390200Z"
    }
   },
   "id": "1e443d261e13320"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "torch.save(model.state_dict(), 'traffic_Sign_Model.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-30T09:24:33.999658900Z",
     "start_time": "2024-10-30T09:24:33.981865800Z"
    }
   },
   "id": "f8b46aba44bc35a7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
